{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['foo', 'bar'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "p_df = pd.DataFrame([(\"foo\", 1), (\"bar\", 2), (\"foo\", 3)], columns=(\"k\", \"v\"))\n",
    "p_df['k'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how to create a Dataframe in pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df = spark.createDataFrame([(\"foo\", 1), (\"bar\", 2), (\"foo\", 3)], ('k', 'v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read csv (as a dataframe) and show it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"Dati/doc1-2015100810.csv\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+----------+------------+--------------------+\n",
      "|CODLINHA|       NOMELINHA|CODVEICULO|NUMEROCARTAO|      DATAUTILIZACAO|\n",
      "+--------+----------------+----------+------------+--------------------+\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0001430250|07/10/15 07:37:02...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0002470195|07/10/15 07:51:25...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0003234514|07/10/15 18:49:49...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0003234514|07/10/15 18:49:51...|\n",
      "|     000|    OPER S/LINHA|     08047|  0000771305|07/10/15 16:47:16...|\n",
      "|     000|    OPER S/LINHA|     08047|  0000856665|07/10/15 16:50:18...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002115218|07/10/15 13:18:26...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002178679|07/10/15 14:18:59...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0000849493|07/10/15 14:40:56...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0000849493|07/10/15 14:41:05...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002202962|07/10/15 16:48:12...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0001839942|07/10/15 18:13:05...|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0003527951|07/10/15 17:07:31...|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0001188263|07/10/15 17:46:36...|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0003260485|07/10/15 17:53:46...|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0002970828|07/10/15 21:27:45...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0003528264|07/10/15 19:25:55...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0003528264|07/10/15 19:25:58...|\n",
      "|     653|          SABARÁ|     HA293|  0003410298|07/10/15 16:15:46...|\n",
      "|     653|          SABARÁ|     HA293|  0002471107|07/10/15 18:44:03...|\n",
      "+--------+----------------+----------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CODLINHA: string (nullable = true)\n",
      " |-- NOMELINHA: string (nullable = true)\n",
      " |-- CODVEICULO: string (nullable = true)\n",
      " |-- NUMEROCARTAO: string (nullable = true)\n",
      " |-- DATAUTILIZACAO: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark, df are from the previous example\n",
    "# Print the schema in a tree format\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|codlinha|\n",
      "+--------+\n",
      "|     280|\n",
      "|     280|\n",
      "|     280|\n",
      "|     280|\n",
      "|     000|\n",
      "|     000|\n",
      "|     629|\n",
      "|     629|\n",
      "|     629|\n",
      "|     629|\n",
      "|     629|\n",
      "|     629|\n",
      "|     814|\n",
      "|     814|\n",
      "|     814|\n",
      "|     814|\n",
      "|     629|\n",
      "|     629|\n",
      "|     653|\n",
      "|     653|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select only the \"codlinha\" column\n",
    "df.select(\"codlinha\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+\n",
      "|codlinha|       nomelinha|\n",
      "+--------+----------------+\n",
      "|     280|N. SRA.DE NAZARÉ|\n",
      "|     280|N. SRA.DE NAZARÉ|\n",
      "|     280|N. SRA.DE NAZARÉ|\n",
      "|     280|N. SRA.DE NAZARÉ|\n",
      "|     000|    OPER S/LINHA|\n",
      "|     000|    OPER S/LINHA|\n",
      "|     629|  ALTO BOQUEIRÃO|\n",
      "|     629|  ALTO BOQUEIRÃO|\n",
      "|     629|  ALTO BOQUEIRÃO|\n",
      "|     629|  ALTO BOQUEIRÃO|\n",
      "|     629|  ALTO BOQUEIRÃO|\n",
      "|     629|  ALTO BOQUEIRÃO|\n",
      "|     814|       MOSSUNGUÊ|\n",
      "|     814|       MOSSUNGUÊ|\n",
      "|     814|       MOSSUNGUÊ|\n",
      "|     814|       MOSSUNGUÊ|\n",
      "|     629|  ALTO BOQUEIRÃO|\n",
      "|     629|  ALTO BOQUEIRÃO|\n",
      "|     653|          SABARÁ|\n",
      "|     653|          SABARÁ|\n",
      "+--------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df['codlinha'], df['nomelinha']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+----------+------------+--------------------+\n",
      "|CODLINHA|       NOMELINHA|CODVEICULO|NUMEROCARTAO|      DATAUTILIZACAO|\n",
      "+--------+----------------+----------+------------+--------------------+\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0001430250|07/10/15 07:37:02...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0002470195|07/10/15 07:51:25...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0003234514|07/10/15 18:49:49...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0003234514|07/10/15 18:49:51...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC947|  0001426341|07/10/15 17:55:07...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BN602|  0001282115|07/10/15 06:29:09...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BN602|  0002883432|07/10/15 15:19:38...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BN602|  0002883432|07/10/15 15:19:43...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BN602|  0003530435|07/10/15 19:22:40...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BN602|  0002025345|07/10/15 22:58:12...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BN602|  0003253117|07/10/15 16:44:16...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0003271986|07/10/15 11:57:16...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC947|  0003268390|07/10/15 18:12:45...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0000312500|07/10/15 08:49:40...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0001627536|07/10/15 12:28:08...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BN602|  0002270052|07/10/15 11:55:10...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC947|  0003006362|07/10/15 18:12:58...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0001135579|07/10/15 12:32:46...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0002239405|07/10/15 07:43:42...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0003387236|07/10/15 07:42:42...|\n",
      "+--------+----------------+----------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['codlinha'] == \"280\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|codlinha|count|\n",
      "+--------+-----+\n",
      "|     467|  608|\n",
      "|     829| 1098|\n",
      "|     870| 2228|\n",
      "|     666|  664|\n",
      "|     TXA|  711|\n",
      "|     475| 1390|\n",
      "|     718|  398|\n",
      "|     030| 4757|\n",
      "|     205| 1711|\n",
      "|     169| 1071|\n",
      "|     334|  374|\n",
      "|     TSP|  904|\n",
      "|     462| 1935|\n",
      "|     711|  769|\n",
      "|     272|  864|\n",
      "|     470|  477|\n",
      "|     232|  805|\n",
      "|     635|  365|\n",
      "|     714|  344|\n",
      "|     ARA| 8965|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"codlinha\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running SQL Queries Programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+----------+------------+--------------------+\n",
      "|CODLINHA|       NOMELINHA|CODVEICULO|NUMEROCARTAO|      DATAUTILIZACAO|\n",
      "+--------+----------------+----------+------------+--------------------+\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0001430250|07/10/15 07:37:02...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0002470195|07/10/15 07:51:25...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0003234514|07/10/15 18:49:49...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0003234514|07/10/15 18:49:51...|\n",
      "|     000|    OPER S/LINHA|     08047|  0000771305|07/10/15 16:47:16...|\n",
      "|     000|    OPER S/LINHA|     08047|  0000856665|07/10/15 16:50:18...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002115218|07/10/15 13:18:26...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002178679|07/10/15 14:18:59...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0000849493|07/10/15 14:40:56...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0000849493|07/10/15 14:41:05...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002202962|07/10/15 16:48:12...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0001839942|07/10/15 18:13:05...|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0003527951|07/10/15 17:07:31...|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0001188263|07/10/15 17:46:36...|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0003260485|07/10/15 17:53:46...|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0002970828|07/10/15 21:27:45...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0003528264|07/10/15 19:25:55...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0003528264|07/10/15 19:25:58...|\n",
      "|     653|          SABARÁ|     HA293|  0003410298|07/10/15 16:15:46...|\n",
      "|     653|          SABARÁ|     HA293|  0002471107|07/10/15 18:44:03...|\n",
      "+--------+----------------+----------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Register the DataFrame as a SQL temporary view\n",
    "df.createOrReplaceTempView(\"people\")\n",
    "\n",
    "sqlDF = spark.sql(\"SELECT * FROM people\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+----------+------------+-------------------+\n",
      "|CODLINHA|       NOMELINHA|CODVEICULO|NUMEROCARTAO|     datautilizacao|\n",
      "+--------+----------------+----------+------------+-------------------+\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0001430250|2015-10-07 07:37:02|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0002470195|2015-10-07 07:51:25|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0003234514|2015-10-07 18:49:49|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0003234514|2015-10-07 18:49:51|\n",
      "|     000|    OPER S/LINHA|     08047|  0000771305|2015-10-07 16:47:16|\n",
      "|     000|    OPER S/LINHA|     08047|  0000856665|2015-10-07 16:50:18|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002115218|2015-10-07 13:18:26|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002178679|2015-10-07 14:18:59|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0000849493|2015-10-07 14:40:56|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0000849493|2015-10-07 14:41:05|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002202962|2015-10-07 16:48:12|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0001839942|2015-10-07 18:13:05|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0003527951|2015-10-07 17:07:31|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0001188263|2015-10-07 17:46:36|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0003260485|2015-10-07 17:53:46|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0002970828|2015-10-07 21:27:45|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0003528264|2015-10-07 19:25:55|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0003528264|2015-10-07 19:25:58|\n",
      "|     653|          SABARÁ|     HA293|  0003410298|2015-10-07 16:15:46|\n",
      "|     653|          SABARÁ|     HA293|  0002471107|2015-10-07 18:44:03|\n",
      "+--------+----------------+----------+------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------+----------------+----------+------------+-------------------+\n",
      "|CODLINHA|       NOMELINHA|CODVEICULO|NUMEROCARTAO|     datautilizacao|\n",
      "+--------+----------------+----------+------------+-------------------+\n",
      "|     000|    OPER S/LINHA|     08047|  0000771305|2015-10-07 16:47:16|\n",
      "|     270|FERNANDO NORONHA|     BN605|  0003525169|2015-10-07 16:47:16|\n",
      "|     619| STA. RITA / CIC|     HA600|  0000983434|2015-10-07 16:47:16|\n",
      "|     OPC| OP. CONTIGENCIA|     MN402|  0003249566|2015-10-07 16:47:16|\n",
      "|     000|    OPER S/LINHA|     07020|  0001627997|2015-10-07 16:47:16|\n",
      "|     000|    OPER S/LINHA|     09029|  0002427443|2015-10-07 16:47:16|\n",
      "+--------+----------------+----------+------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, unix_timestamp, to_date, to_timestamp\n",
    "\n",
    "df_timestamp = df.withColumn('datautilizacao', to_timestamp(unix_timestamp(col('datautilizacao'), 'dd/MM/yy HH:mm:ss').cast(\"timestamp\")))\n",
    "\n",
    "df_timestamp.show()\n",
    "\n",
    "df_timestamp.createOrReplaceTempView(\"people_timestamp\")\n",
    "\n",
    "sqlDF = spark.sql(\"SELECT * FROM people_timestamp WHERE datautilizacao == '2015-10-07 16:47:16'\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Temporary View"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temporary views in Spark SQL are session-scoped and will disappear if the session that creates it terminates. If you want to have a temporary view that is shared among all sessions and keep alive until the Spark application terminates, you can create a global temporary view. Global temporary view is tied to a system preserved database global_temp, and we must use the qualified name to refer it, e.g. SELECT * FROM global_temp.view1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+----------+------------+--------------------+\n",
      "|CODLINHA|       NOMELINHA|CODVEICULO|NUMEROCARTAO|      DATAUTILIZACAO|\n",
      "+--------+----------------+----------+------------+--------------------+\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0001430250|07/10/15 07:37:02...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0002470195|07/10/15 07:51:25...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0003234514|07/10/15 18:49:49...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0003234514|07/10/15 18:49:51...|\n",
      "|     000|    OPER S/LINHA|     08047|  0000771305|07/10/15 16:47:16...|\n",
      "|     000|    OPER S/LINHA|     08047|  0000856665|07/10/15 16:50:18...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002115218|07/10/15 13:18:26...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002178679|07/10/15 14:18:59...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0000849493|07/10/15 14:40:56...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0000849493|07/10/15 14:41:05...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002202962|07/10/15 16:48:12...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0001839942|07/10/15 18:13:05...|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0003527951|07/10/15 17:07:31...|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0001188263|07/10/15 17:46:36...|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0003260485|07/10/15 17:53:46...|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0002970828|07/10/15 21:27:45...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0003528264|07/10/15 19:25:55...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0003528264|07/10/15 19:25:58...|\n",
      "|     653|          SABARÁ|     HA293|  0003410298|07/10/15 16:15:46...|\n",
      "|     653|          SABARÁ|     HA293|  0002471107|07/10/15 18:44:03...|\n",
      "+--------+----------------+----------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Register the DataFrame as a global temporary view\n",
    "df.createGlobalTempView(\"people\")\n",
    "\n",
    "# Global temporary view is tied to a system preserved database `global_temp`\n",
    "spark.sql(\"SELECT * FROM global_temp.people\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+----------+------------+--------------------+\n",
      "|CODLINHA|       NOMELINHA|CODVEICULO|NUMEROCARTAO|      DATAUTILIZACAO|\n",
      "+--------+----------------+----------+------------+--------------------+\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0001430250|07/10/15 07:37:02...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0002470195|07/10/15 07:51:25...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0003234514|07/10/15 18:49:49...|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0003234514|07/10/15 18:49:51...|\n",
      "|     000|    OPER S/LINHA|     08047|  0000771305|07/10/15 16:47:16...|\n",
      "|     000|    OPER S/LINHA|     08047|  0000856665|07/10/15 16:50:18...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002115218|07/10/15 13:18:26...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002178679|07/10/15 14:18:59...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0000849493|07/10/15 14:40:56...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0000849493|07/10/15 14:41:05...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002202962|07/10/15 16:48:12...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0001839942|07/10/15 18:13:05...|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0003527951|07/10/15 17:07:31...|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0001188263|07/10/15 17:46:36...|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0003260485|07/10/15 17:53:46...|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0002970828|07/10/15 21:27:45...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0003528264|07/10/15 19:25:55...|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0003528264|07/10/15 19:25:58...|\n",
      "|     653|          SABARÁ|     HA293|  0003410298|07/10/15 16:15:46...|\n",
      "|     653|          SABARÁ|     HA293|  0002471107|07/10/15 18:44:03...|\n",
      "+--------+----------------+----------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Global temporary view is cross-session\n",
    "spark.newSession().sql(\"SELECT * FROM global_temp.people\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interoperating with RDDs\n",
    "Spark SQL supports two different methods for converting existing RDDs into Datasets. The first method uses reflection to infer the schema of an RDD that contains specific types of objects. This reflection based approach leads to more concise code and works well when you already know the schema while writing your Spark application.\n",
    "\n",
    "The second method for creating Datasets is through a programmatic interface that allows you to construct a schema and then apply it to an existing RDD. While this method is more verbose, it allows you to construct Datasets when the columns and their types are not known until runtime.\n",
    "\n",
    "### Inferring the Schema Using Reflection (DOESN'T WORK AND I DON'T KNOW WHY, BUT THIS IS NOT IMPORTANT)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Load a text file and convert each line to a Row.\n",
    "lines = sc.textFile(\"Dati/ciao.txt\")\n",
    "parts = lines.map(lambda l: l.split(\",\"))\n",
    "people2 = parts.map(lambda p: Row(codlinha=p[0], nomelinha=p[1], codveiculo=p[2], numerocartao=int(p[3]), datautilizacao=p[4], orautilizacao=p[5]))\n",
    "\n",
    "# Infer the schema, and register the DataFrame as a table.\n",
    "schemaPeople = spark.createDataFrame(people2)\n",
    "schemaPeople.createOrReplaceTempView(\"people2\")\n",
    "\n",
    "# SQL can be run over DataFrames that have been registered as a table.\n",
    "person = spark.sql(\"SELECT codlinha FROM people2 WHERE numerocartao == 0001430250\")\n",
    "\n",
    "person.show()\n",
    "\n",
    "# The results of SQL queries are Dataframe objects.\n",
    "# rdd returns the content as an :class:`pyspark.RDD` of :class:`Row`.\n",
    "#codice = person.rdd.map(lambda p: \"Name: \" + p.codlinha).collect()\n",
    "#for codlinha in codice:\n",
    "#    print(codlinha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST WITH THE LAST DATETIME COLUMN DIVIDED\n",
    "\n",
    "I divided the last column in two (one for date and other for time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+----------+------------+--------------+-------------+\n",
      "|CODLINHA|       NOMELINHA|CODVEICULO|NUMEROCARTAO|DATAUTILIZACAO|ORAUTILIZACAO|\n",
      "+--------+----------------+----------+------------+--------------+-------------+\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0001430250|      07/10/15|     07:37:02|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0002470195|      07/10/15|     07:51:25|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0003234514|      07/10/15|     18:49:49|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0003234514|      07/10/15|     18:49:51|\n",
      "|     000|    OPER S/LINHA|     08047|  0000771305|      07/10/15|     16:47:16|\n",
      "|     000|    OPER S/LINHA|     08047|  0000856665|      07/10/15|     16:50:18|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002115218|      07/10/15|     13:18:26|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002178679|      07/10/15|     14:18:59|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0000849493|      07/10/15|     14:40:56|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0000849493|      07/10/15|     14:41:05|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002202962|      07/10/15|     16:48:12|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0001839942|      07/10/15|     18:13:05|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0003527951|      07/10/15|     17:07:31|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0001188263|      07/10/15|     17:46:36|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0003260485|      07/10/15|     17:53:46|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0002970828|      07/10/15|     21:27:45|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0003528264|      07/10/15|     19:25:55|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0003528264|      07/10/15|     19:25:58|\n",
      "|     653|          SABARÁ|     HA293|  0003410298|      07/10/15|     16:15:46|\n",
      "|     653|          SABARÁ|     HA293|  0002471107|      07/10/15|     18:44:03|\n",
      "+--------+----------------+----------+------------+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- CODLINHA: string (nullable = true)\n",
      " |-- NOMELINHA: string (nullable = true)\n",
      " |-- CODVEICULO: string (nullable = true)\n",
      " |-- NUMEROCARTAO: string (nullable = true)\n",
      " |-- DATAUTILIZACAO: string (nullable = true)\n",
      " |-- ORAUTILIZACAO: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test = spark.read.csv(\"Dati/ciao.csv\", header = True)\n",
    "df_test.show()\n",
    "df_test.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert column String to Datetime into the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+----------+------------+--------------+-------------+\n",
      "|CODLINHA|       NOMELINHA|CODVEICULO|NUMEROCARTAO|datautilizacao|ORAUTILIZACAO|\n",
      "+--------+----------------+----------+------------+--------------+-------------+\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0001430250|    2015-10-07|     07:37:02|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0002470195|    2015-10-07|     07:51:25|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0003234514|    2015-10-07|     18:49:49|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0003234514|    2015-10-07|     18:49:51|\n",
      "|     000|    OPER S/LINHA|     08047|  0000771305|    2015-10-07|     16:47:16|\n",
      "|     000|    OPER S/LINHA|     08047|  0000856665|    2015-10-07|     16:50:18|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002115218|    2015-10-07|     13:18:26|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002178679|    2015-10-07|     14:18:59|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0000849493|    2015-10-07|     14:40:56|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0000849493|    2015-10-07|     14:41:05|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002202962|    2015-10-07|     16:48:12|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0001839942|    2015-10-07|     18:13:05|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0003527951|    2015-10-07|     17:07:31|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0001188263|    2015-10-07|     17:46:36|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0003260485|    2015-10-07|     17:53:46|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0002970828|    2015-10-07|     21:27:45|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0003528264|    2015-10-07|     19:25:55|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0003528264|    2015-10-07|     19:25:58|\n",
      "|     653|          SABARÁ|     HA293|  0003410298|    2015-10-07|     16:15:46|\n",
      "|     653|          SABARÁ|     HA293|  0002471107|    2015-10-07|     18:44:03|\n",
      "+--------+----------------+----------+------------+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- CODLINHA: string (nullable = true)\n",
      " |-- NOMELINHA: string (nullable = true)\n",
      " |-- CODVEICULO: string (nullable = true)\n",
      " |-- NUMEROCARTAO: string (nullable = true)\n",
      " |-- datautilizacao: date (nullable = true)\n",
      " |-- ORAUTILIZACAO: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_datetime = df_test.withColumn('datautilizacao', to_date(unix_timestamp(col('datautilizacao'), 'dd/MM/yy').cast(\"timestamp\")))\n",
    "\n",
    "df_datetime.show()\n",
    "df_datetime.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert String to Datetime (but the result is another column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|datautilizacao|\n",
      "+--------------+\n",
      "|    2015-10-07|\n",
      "|    2015-10-07|\n",
      "|    2015-10-07|\n",
      "|    2015-10-07|\n",
      "|    2015-10-07|\n",
      "|    2015-10-07|\n",
      "|    2015-10-07|\n",
      "|    2015-10-07|\n",
      "|    2015-10-07|\n",
      "|    2015-10-07|\n",
      "|    2015-10-07|\n",
      "|    2015-10-07|\n",
      "|    2015-10-07|\n",
      "|    2015-10-07|\n",
      "|    2015-10-07|\n",
      "|    2015-10-07|\n",
      "|    2015-10-07|\n",
      "|    2015-10-07|\n",
      "|    2015-10-07|\n",
      "|    2015-10-07|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- datautilizacao: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "#df_test = df_test.withColumn(\"datautilizacao\", df_test[\"datautilizacao\"].cast(StringType()))\n",
    "\n",
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "df_test3 = df_test.select(to_date('datautilizacao', 'dd/MM/yy').alias('datautilizacao'))\n",
    "#df_test.select(to_date(df_test.datautilizacao, 'dd/MM/yy').alias('datautilizacao'))\n",
    "\n",
    "df_test3.show()\n",
    "df_test3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL with Datatime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|codlinha|\n",
      "+--------+\n",
      "|     280|\n",
      "|     280|\n",
      "|     280|\n",
      "|     280|\n",
      "|     000|\n",
      "|     000|\n",
      "|     629|\n",
      "|     629|\n",
      "|     629|\n",
      "|     629|\n",
      "|     629|\n",
      "|     629|\n",
      "|     814|\n",
      "|     814|\n",
      "|     814|\n",
      "|     814|\n",
      "|     629|\n",
      "|     629|\n",
      "|     653|\n",
      "|     653|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------+----------------+----------+------------+--------------+-------------+\n",
      "|CODLINHA|       NOMELINHA|CODVEICULO|NUMEROCARTAO|datautilizacao|ORAUTILIZACAO|\n",
      "+--------+----------------+----------+------------+--------------+-------------+\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0001430250|    2015-10-07|     07:37:02|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0002470195|    2015-10-07|     07:51:25|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0003234514|    2015-10-07|     18:49:49|\n",
      "|     280|N. SRA.DE NAZARÉ|     BC911|  0003234514|    2015-10-07|     18:49:51|\n",
      "|     000|    OPER S/LINHA|     08047|  0000771305|    2015-10-07|     16:47:16|\n",
      "|     000|    OPER S/LINHA|     08047|  0000856665|    2015-10-07|     16:50:18|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002115218|    2015-10-07|     13:18:26|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002178679|    2015-10-07|     14:18:59|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0000849493|    2015-10-07|     14:40:56|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0000849493|    2015-10-07|     14:41:05|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0002202962|    2015-10-07|     16:48:12|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0001839942|    2015-10-07|     18:13:05|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0003527951|    2015-10-07|     17:07:31|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0001188263|    2015-10-07|     17:46:36|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0003260485|    2015-10-07|     17:53:46|\n",
      "|     814|       MOSSUNGUÊ|     LN404|  0002970828|    2015-10-07|     21:27:45|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0003528264|    2015-10-07|     19:25:55|\n",
      "|     629|  ALTO BOQUEIRÃO|     KA603|  0003528264|    2015-10-07|     19:25:58|\n",
      "|     653|          SABARÁ|     HA293|  0003410298|    2015-10-07|     16:15:46|\n",
      "|     653|          SABARÁ|     HA293|  0002471107|    2015-10-07|     18:44:03|\n",
      "+--------+----------------+----------+------------+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_datetime.createOrReplaceTempView(\"people_test\")\n",
    "\n",
    "sqlDF = spark.sql(\"SELECT codlinha FROM people_test WHERE datautilizacao == '2015-10-07'\")\n",
    "sqlDF.show()\n",
    "\n",
    "df_datetime.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
